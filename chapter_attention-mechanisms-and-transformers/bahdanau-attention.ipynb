{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunshineGreeny/Dive-into-deep-learning-Pytorch/blob/colab-experiments/chapter_attention-mechanisms-and-transformers/bahdanau-attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d37bdd",
      "metadata": {
        "id": "e3d37bdd"
      },
      "source": [
        "# The Bahdanau Attention Mechanism\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "64405f0b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:13.059684Z",
          "iopub.status.busy": "2023-08-18T19:46:13.058589Z",
          "iopub.status.idle": "2023-08-18T19:46:16.109138Z",
          "shell.execute_reply": "2023-08-18T19:46:16.108090Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "64405f0b"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from collections import Counter\n",
        "import re\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tools"
      ],
      "metadata": {
        "id": "PUdSD4Ch_Coc"
      },
      "id": "PUdSD4Ch_Coc"
    },
    {
      "cell_type": "code",
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"返回可用的GPU，否则返回CPU\"\"\"\n",
        "    if torch.cuda.device_count() >= i+1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')\n",
        "\n",
        "\n",
        "class MTFraEng(torch.utils.data.Dataset):\n",
        "    def __init__(self, src_texts, tgt_texts, num_steps=10, reserved_tokens=None):\n",
        "        self.src_tokens = [self._preprocess(t) for t in src_texts]\n",
        "        self.tgt_tokens = [self._preprocess(t) for t in tgt_texts]\n",
        "        self.src_vocab = self._build_vocab(self.src_tokens, reserved_tokens)\n",
        "        self.tgt_vocab = self._build_vocab(self.tgt_tokens, reserved_tokens)\n",
        "        self.num_steps = num_steps\n",
        "        self.src_array = self._build_array(self.src_tokens, self.src_vocab, num_steps)\n",
        "        self.tgt_array = self._build_array(self.tgt_tokens, self.tgt_vocab, num_steps)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_array)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src_array[idx], self.tgt_array[idx]\n",
        "\n",
        "    @staticmethod\n",
        "    def _preprocess(text):\n",
        "        text = text.lower().strip()\n",
        "        text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
        "        text = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", text)\n",
        "        return text.split()\n",
        "\n",
        "    @staticmethod\n",
        "    def _build_vocab(tokens_list, reserved_tokens=None, min_freq=1):\n",
        "        counter = Counter([tk for line in tokens_list for tk in line])\n",
        "        token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "        idx_to_token = ['<pad>', '<bos>', '<eos>'] + (reserved_tokens or [])\n",
        "        idx_to_token += [tk for tk, freq in token_freqs if freq >= min_freq and tk not in idx_to_token]\n",
        "        token_to_idx = {tk: idx for idx, tk in enumerate(idx_to_token)}\n",
        "        return {\"idx_to_token\": idx_to_token, \"token_to_idx\": token_to_idx}\n",
        "\n",
        "    @staticmethod\n",
        "    def _build_array(lines, vocab, num_steps):\n",
        "        bos, eos, pad = vocab[\"token_to_idx\"][\"<bos>\"], vocab[\"token_to_idx\"][\"<eos>\"], vocab[\"token_to_idx\"][\"<pad>\"]\n",
        "        array = []\n",
        "        for line in lines:\n",
        "            arr = [bos] + [vocab[\"token_to_idx\"].get(w, pad) for w in line] + [eos]\n",
        "            if len(arr) < num_steps:\n",
        "                arr += [pad] * (num_steps - len(arr))\n",
        "            else:\n",
        "                arr = arr[:num_steps-1] + [eos]  # 保证最后是 eos\n",
        "            array.append(arr)\n",
        "        return torch.tensor(array)\n",
        "\n",
        "\n",
        "def bleu(preq_seq,label_seq,k=2):\n",
        "  return sentence_bleu([label_seq.split()],\n",
        "             preq_seq.split(),\n",
        "             smoothing_function=SmoothingFunction().method1,\n",
        "             weights=tuple[1/k]*k)\n",
        "\n",
        "\n",
        "class AddictiveAttention(nn.Module):\n",
        "  def __init__(self,num_hiddens,dropout=0.):\n",
        "    super().__init__()\n",
        "    self.W_q=nn.Linear(num_hiddens,num_hiddens,bias=False)\n",
        "    self.W_k=nn.Linear(num_hiddens,num_hiddens,bias=False)\n",
        "    self.W_v=nn.Linear(num_hiddens,1,bias=False)\n",
        "    self.dropout=nn.Dropout(dropout)\n",
        "    self.attention_weights=None\n",
        "\n",
        "  def forward(self,queries,keys,values,valid_lens=None):\n",
        "    queries,keys=self.W_q(queries),self.W_k(keys)\n",
        "    features=queries.unsqueeze(2)+keys.unsqueeze(1)\n",
        "    scores=self.W_v(torch.tanh(features)).squeeze(-1)\n",
        "    if valid_lens is not None:\n",
        "      mask=torch.arange(keys.shape[1],device=keys.device)[None,:]>=valid_lens[:,None]\n",
        "      scores=scores.masked_fill(mask[:,None],-1e6)\n",
        "    self.attention_weights=F.softmax(scores,dim=-1)\n",
        "    return torch.bmm(self.dropout(self.attention_weights),values)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def init_state(self,enc_outputs,*args):\n",
        "    raise NotImplementedError\n",
        "  def forward(self,X,state):\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "class Seq2SeqEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.LSTM(embed_size, num_hiddens, num_layers,\n",
        "                           dropout=dropout, batch_first=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.embedding(X)\n",
        "        output, state = self.rnn(X)\n",
        "        return output, state  # output: (B, T, H), state: (h_n, c_n)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        enc_outputs = self.encoder(src)\n",
        "        dec_state = self.decoder.init_state(enc_outputs)\n",
        "        dec_input = tgt[:, :-1]\n",
        "        logits, _ = self.decoder(dec_input, dec_state, enc_outputs)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def init_seq2seq(src_vocab_size, tgt_vocab_size, embed_size=256, num_hiddens=256, num_layers=2, dropout=0.1):\n",
        "    encoder = Seq2SeqEncoder(src_vocab_size, embed_size, num_hiddens, num_layers, dropout)\n",
        "    decoder = Seq2SeqAttentionDecoder(tgt_vocab_size, embed_size, num_hiddens, num_layers, dropout)\n",
        "    return Seq2Seq(encoder, decoder)\n",
        "\n",
        "\n",
        "def check_shape(tensor, expected_shape):\n",
        "    assert tensor.shape == expected_shape, \\\n",
        "        f'Expected shape: {expected_shape}, got: {tensor.shape}'\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n",
        "                  cmap='Reds'):\n",
        "    \"\"\"Show heatmaps of matrices.\"\"\"\n",
        "    num_rows,num_cols=matrices.shape[0],matrices.shape[1]\n",
        "    # 创建子图网络\n",
        "    fig,axes=plt.subplots(num_rows,num_cols,figsize=figsize,\n",
        "                          sharex=True,sharey=True,squeeze=False)\n",
        "    # 遍历所有矩阵并绘制热力图\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            ax=axes[i,j]\n",
        "            # 将张量转换为numpy数组并分离计算图\n",
        "            matrix=matrices[i,j].detach().numpy()\n",
        "\n",
        "            # 使用热力图显示矩阵\n",
        "            pcm=ax.imshow(matrix,cmap='Reds')\n",
        "\n",
        "            # 设置坐标轴标签\n",
        "            if i==num_rows-1:#最后一行显示x轴标签\n",
        "                ax.set_xlabel(xlabel)\n",
        "            if j==0:#第一列显示y轴标签\n",
        "                ax.set_ylabel(ylabel)\n",
        "            if titles:\n",
        "                ax.set_title(titles[j])\n",
        "\n",
        "            # 隐藏刻度线\n",
        "            ax.xaxis.set_ticks_position('none')\n",
        "            ax.yaxis.set_ticks_position('none')\n",
        "\n",
        "    # Add a colorbar\n",
        "    fig.colorbar(pcm, ax=axes.ravel().tolist())\n",
        "    plt.show()\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, lr=0.005, device=None):\n",
        "        self.device = torch.device('cpu') # Explicitly set device to CPU\n",
        "        self.model = model.to(self.device)\n",
        "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "    def fit(self, train_iter, num_epochs=5):\n",
        "        for epoch in range(num_epochs):\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            for src, tgt in train_iter:\n",
        "                src, tgt = src.to(self.device), tgt.to(self.device)\n",
        "                logits = self.model(src, tgt)\n",
        "                y = tgt[:,1:].reshape(-1)\n",
        "                l = self.loss_fn(logits.reshape(-1, logits.shape[-1]), y)\n",
        "                self.optimizer.zero_grad()\n",
        "                l.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n",
        "                self.optimizer.step()\n",
        "                total_loss += l.item()\n",
        "            print(f\"epoch {epoch+1}, loss {total_loss/len(train_iter):.3f}\")"
      ],
      "metadata": {
        "id": "ZROEqn5Mvte9"
      },
      "id": "ZROEqn5Mvte9",
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b7a2c46a",
      "metadata": {
        "id": "b7a2c46a"
      },
      "source": [
        "The base interface for decoders with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "7392fc80",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:16.115524Z",
          "iopub.status.busy": "2023-08-18T19:46:16.114277Z",
          "iopub.status.idle": "2023-08-18T19:46:16.121848Z",
          "shell.execute_reply": "2023-08-18T19:46:16.120397Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "7392fc80"
      },
      "outputs": [],
      "source": [
        "class AttentionDecoder(Decoder):\n",
        "    \"\"\"The base attention-based decoder interface.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a94603f",
      "metadata": {
        "id": "7a94603f"
      },
      "source": [
        "Implement the RNN decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "f0a3f536",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:16.128312Z",
          "iopub.status.busy": "2023-08-18T19:46:16.125898Z",
          "iopub.status.idle": "2023-08-18T19:46:16.142962Z",
          "shell.execute_reply": "2023-08-18T19:46:16.141775Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "f0a3f536"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0):\n",
        "        super().__init__()\n",
        "        self.attention = AddictiveAttention(num_hiddens, dropout)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(\n",
        "            embed_size + num_hiddens, num_hiddens, num_layers,\n",
        "            dropout=dropout)\n",
        "        self.dense = nn.LazyLinear(vocab_size)\n",
        "        # The original code had init_seq2seq here, which is not defined for the decoder.\n",
        "        # Removing this line.\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_hidden_state, enc_valid_lens):\n",
        "        return (enc_outputs.permute(1, 0, 2), enc_hidden_state, enc_valid_lens)\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        enc_outputs, hidden_state, enc_valid_lens = state\n",
        "        X = self.embedding(X).permute(1, 0, 2)\n",
        "        outputs, self._attention_weights = [], []\n",
        "        for x in X:\n",
        "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
        "            context = self.attention(\n",
        "                query, enc_outputs, enc_outputs, enc_valid_lens)\n",
        "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
        "            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)\n",
        "            outputs.append(out)\n",
        "            self._attention_weights.append(self.attention.attention_weights)\n",
        "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
        "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
        "                                          enc_valid_lens]\n",
        "\n",
        "    @property\n",
        "    def attention_weights(self):\n",
        "        return self._attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4db11b4",
      "metadata": {
        "id": "b4db11b4"
      },
      "source": [
        "Test the implemented\n",
        "decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "e7d6e370",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:16.149119Z",
          "iopub.status.busy": "2023-08-18T19:46:16.148126Z",
          "iopub.status.idle": "2023-08-18T19:46:16.201990Z",
          "shell.execute_reply": "2023-08-18T19:46:16.200456Z"
        },
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "e7d6e370",
        "outputId": "9038f1f9-d341-4a93-9595-e9071b68162d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (4) must match the size of tensor b (7) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1747113572.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Pass enc_outputs, enc_hidden_state, and enc_valid_lens to init_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-29753455.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, state)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             context = self.attention(\n\u001b[0m\u001b[1;32m     24\u001b[0m                 query, enc_outputs, enc_outputs, enc_valid_lens)\n\u001b[1;32m     25\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2485022875.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, queries, keys, values, valid_lens)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_lens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mvalid_lens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (7) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "vocab_size, embed_size, num_hiddens, num_layers = 10, 8, 16, 2\n",
        "batch_size, num_steps = 4, 7\n",
        "encoder = Seq2SeqEncoder(vocab_size, embed_size, num_hiddens, num_layers)\n",
        "decoder = Seq2SeqAttentionDecoder(vocab_size, embed_size, num_hiddens,\n",
        "                                  num_layers)\n",
        "X = torch.zeros((batch_size, num_steps), dtype=torch.long)\n",
        "enc_outputs, enc_hidden_state = encoder(X)\n",
        "# Pass enc_outputs, enc_hidden_state, and enc_valid_lens to init_state\n",
        "state = decoder.init_state(enc_outputs, enc_hidden_state, torch.tensor([num_steps] * batch_size))\n",
        "output, state = decoder(X, state)\n",
        "check_shape(output, (batch_size, num_steps, vocab_size))\n",
        "check_shape(state[0], (batch_size, num_steps, num_hiddens))\n",
        "check_shape(state[1][0], (batch_size, num_hiddens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6016043c",
      "metadata": {
        "id": "6016043c"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "a73f9cc6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:16.207768Z",
          "iopub.status.busy": "2023-08-18T19:46:16.207253Z",
          "iopub.status.idle": "2023-08-18T19:46:52.077164Z",
          "shell.execute_reply": "2023-08-18T19:46:52.076268Z"
        },
        "origin_pos": 16,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "a73f9cc6",
        "outputId": "cc5b6cdf-e47a-4c6e-a2c3-f51fd9679370"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1683961636.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Removed tgt_pad and lr as they are not in Seq2Seq constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass lr to Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Changed data to train_loader and added num_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2485022875.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_iter, num_epochs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2485022875.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0menc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mdec_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2485022875.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m  \u001b[0;31m# output: (B, T, H), state: (h_n, c_n)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2544\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ],
      "source": [
        "# Placeholder data - Replace with your actual source and target sentences\n",
        "src_texts = [\"I am a student.\", \"He likes apples.\", \"She is reading.\"]\n",
        "tgt_texts = [\"Je suis étudiant.\", \"Il aime les pommes.\", \"Elle lit.\"]\n",
        "num_steps = 10\n",
        "batch_size = 2\n",
        "\n",
        "dataset = MTFraEng(src_texts, tgt_texts, num_steps=num_steps)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "embed_size, num_hiddens, num_layers, dropout = 256, 256, 2, 0.2\n",
        "encoder = Seq2SeqEncoder(\n",
        "    len(data.src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "decoder = Seq2SeqAttentionDecoder(\n",
        "    len(data.tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "model = Seq2Seq(encoder, decoder) # Removed tgt_pad and lr as they are not in Seq2Seq constructor\n",
        "trainer = Trainer(model, lr=0.005) # Pass lr to Trainer\n",
        "trainer.fit(train_loader, num_epochs=30) # Changed data to train_loader and added num_epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085c7e96",
      "metadata": {
        "id": "085c7e96"
      },
      "source": [
        "Translate a few English sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "a22c2296",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:52.082122Z",
          "iopub.status.busy": "2023-08-18T19:46:52.081526Z",
          "iopub.status.idle": "2023-08-18T19:46:52.108612Z",
          "shell.execute_reply": "2023-08-18T19:46:52.107700Z"
        },
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "a22c2296",
        "outputId": "91a3eb89-5812-44e4-f1e6-d0b24b7650b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Seq2Seq' object has no attribute 'predict_step'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3458784906.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mengs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'go .'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'i lost .'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'he\\'s calm .'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'i\\'m home .'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'va !'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'j\\'ai perdu .'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'il est calme .'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'je suis chez moi .'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m preds, _ = model.predict_step(\n\u001b[0m\u001b[1;32m      4\u001b[0m     data.build(engs, fras), try_gpu(), data.num_steps)\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1963\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Seq2Seq' object has no attribute 'predict_step'"
          ]
        }
      ],
      "source": [
        "engs = ['go .', 'i lost .', 'he\\'s calm .', 'i\\'m home .']\n",
        "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
        "preds, _ = model.predict_step(\n",
        "    data.build(engs, fras), try_gpu(), data.num_steps)\n",
        "for en, fr, p in zip(engs, fras, preds):\n",
        "    translation = []\n",
        "    for token in data.tgt_vocab.to_tokens(p):\n",
        "        if token == '<eos>':\n",
        "            break\n",
        "        translation.append(token)\n",
        "    print(f'{en} => {translation}, bleu,'\n",
        "          f'{bleu(\" \".join(translation), fr, k=2):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7470cbee",
      "metadata": {
        "id": "7470cbee"
      },
      "source": [
        "Visualize the attention weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9c665a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:46:52.134058Z",
          "iopub.status.busy": "2023-08-18T19:46:52.133495Z",
          "iopub.status.idle": "2023-08-18T19:46:52.369882Z",
          "shell.execute_reply": "2023-08-18T19:46:52.368741Z"
        },
        "origin_pos": 22,
        "tab": [
          "pytorch"
        ],
        "id": "e9c665a8"
      },
      "outputs": [],
      "source": [
        "_, dec_attention_weights = model.predict_step(\n",
        "    data.build([engs[-1]], [fras[-1]]), try_gpu(), data.num_steps, True)\n",
        "attention_weights = torch.cat(\n",
        "    [step[0][0][0] for step in dec_attention_weights], 0)\n",
        "attention_weights = attention_weights.reshape((1, 1, -1, data.num_steps))\n",
        "\n",
        "show_heatmaps(\n",
        "    attention_weights[:, :, :, :len(engs[-1].split()) + 1].cpu(),\n",
        "    xlabel='Key positions', ylabel='Query positions')"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "rise": {
      "autolaunch": true,
      "enable_chalkboard": true,
      "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
      "scroll": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}