{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunshineGreeny/Dive-into-deep-learning-Pytorch/blob/colab-experiments/chapter_attention-mechanisms-and-transformers/attention-scoring-functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6a0ffe1",
      "metadata": {
        "id": "f6a0ffe1"
      },
      "source": [
        "# Attention Scoring Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9440ec4c",
      "metadata": {
        "id": "9440ec4c"
      },
      "source": [
        "Dot Product Attention\n",
        "Masked Softmax Operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8e33a108",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:45.433072Z",
          "iopub.status.busy": "2023-08-18T19:43:45.432523Z",
          "iopub.status.idle": "2023-08-18T19:43:48.504425Z",
          "shell.execute_reply": "2023-08-18T19:43:48.503548Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "8e33a108"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_shape(tensor, expected_shape):\n",
        "    \"\"\"\n",
        "    检查张量形状是否与预期形状匹配\n",
        "\n",
        "    参数:\n",
        "        tensor: 要检查的张量\n",
        "        expected_shape: 预期的形状元组\n",
        "\n",
        "    返回:\n",
        "        如果形状匹配，返回原张量；否则抛出断言错误\n",
        "    \"\"\"\n",
        "    assert tensor.shape == expected_shape, \\\n",
        "        f\"Expected shape: {expected_shape}, but got: {tensor.shape}\"\n",
        "    return tensor\n",
        "\n",
        "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(3.5, 2.5),\n",
        "                  sharex=True,sharey=True,squeeze=False):\n",
        "    \"\"\"\n",
        "    显示注意力权重的热力图\n",
        "\n",
        "    参数:\n",
        "        matrices: 注意力权重矩阵，形状为 (行数, 列数, 矩阵高度, 矩阵宽度)\n",
        "        xlabel: x轴标签（通常是\"Keys\"）\n",
        "        ylabel: y轴标签（通常是\"Queries\"）\n",
        "        titles: 可选的子图标题\n",
        "        figsize: 图形大小\n",
        "    \"\"\"\n",
        "    num_rows,num_cols=matrices.shape[0],matrices.shape[1]\n",
        "\n",
        "    # 创建子图网络\n",
        "    fig,axes=plt.subplots(num_rows,num_cols,figsize=figsize,\n",
        "                          sharex=True,sharey=True,squeeze=False)\n",
        "    # 遍历所有矩阵并绘制热力图\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            ax=axes[i,j]\n",
        "            # 将张量转换为numpy数组并分离计算图\n",
        "            matrix=matrices[i,j].detach().numpy()\n",
        "\n",
        "            # 使用热力图显示矩阵\n",
        "            pcm=ax.imshow(matrix,cmap='Reds')\n",
        "\n",
        "            # 设置坐标轴标签\n",
        "            if i==num_rows-1:#最后一行显示x轴标签\n",
        "                ax.set_xlabel(xlabel)\n",
        "            if j==0:#第一列显示y轴标签\n",
        "                ax.set_ylabel(ylabel)\n",
        "            if titles:\n",
        "                ax.set_title(titles[j])\n",
        "\n",
        "            # 隐藏刻度线\n",
        "            ax.xaxis.set_ticks_position('none')\n",
        "            ax.yaxis.set_ticks_position('none')\n",
        "\n",
        "    # Add a colorbar\n",
        "    fig.colorbar(pcm, ax=axes.ravel().tolist())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qX8imPZrMywU"
      },
      "id": "qX8imPZrMywU",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "080c4919",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.508521Z",
          "iopub.status.busy": "2023-08-18T19:43:48.507880Z",
          "iopub.status.idle": "2023-08-18T19:43:48.515032Z",
          "shell.execute_reply": "2023-08-18T19:43:48.514260Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ],
        "id": "080c4919"
      },
      "outputs": [],
      "source": [
        "def masked_softmax(X, valid_lens):\n",
        "    \"\"\"\n",
        "    带掩码的softmax操作：对最后一个轴进行softmax，同时掩码掉无效位置\n",
        "\n",
        "    参数:\n",
        "        X: 输入张量，形状为 (batch_size, 序列长度, 特征维度)\n",
        "        valid_lens: 有效长度，可以是标量或张量\n",
        "\n",
        "    返回:\n",
        "        应用了掩码和softmax后的张量\n",
        "    \"\"\"\n",
        "    def _sequence_mask(X, valid_len, value=0):\n",
        "        \"\"\"\n",
        "        内部函数：创建序列掩码\n",
        "\n",
        "        参数:\n",
        "            X: 输入张量\n",
        "            valid_len: 每个序列的有效长度\n",
        "            value: 掩码位置填充的值\n",
        "\n",
        "        返回:\n",
        "            应用了掩码的张量\n",
        "        \"\"\"\n",
        "        maxlen = X.size(1)\n",
        "\n",
        "        # 创建掩码：对于每个位置，如果索引小于有效长度则为True，否则为False\n",
        "        mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                            device=X.device)[None, :] < valid_len[:, None]\n",
        "\n",
        "        # 将掩码为False的位置设置为指定的值\n",
        "        X[~mask] = value\n",
        "        return X\n",
        "\n",
        "    # 没有提供有效长度，直接返回标准sofemax\n",
        "    if valid_lens is None:\n",
        "        return nn.functional.softmax(X, dim=-1)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "\n",
        "        # 处理不同维度的有效长度\n",
        "        if valid_lens.dim() == 1:\n",
        "            # 如果是一维,复制到每个位置\n",
        "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
        "        else:\n",
        "            # 如果是二维,展平\n",
        "            valid_lens = valid_lens.reshape(-1)\n",
        "\n",
        "        # 应用序列掩码,将无效位置设置为很小的值\n",
        "        X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
        "\n",
        "        # 应用softmax并恢复原始形状\n",
        "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7b144c",
      "metadata": {
        "id": "ca7b144c"
      },
      "source": [
        "Illustrate how this function works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0fb493b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.518456Z",
          "iopub.status.busy": "2023-08-18T19:43:48.517778Z",
          "iopub.status.idle": "2023-08-18T19:43:48.554108Z",
          "shell.execute_reply": "2023-08-18T19:43:48.553283Z"
        },
        "origin_pos": 13,
        "tab": [
          "pytorch"
        ],
        "id": "b0fb493b",
        "outputId": "2fdd17c7-8e7c-49c8-ae08-3483dc413176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.4448, 0.5552, 0.0000, 0.0000],\n",
              "         [0.4032, 0.5968, 0.0000, 0.0000]],\n",
              "\n",
              "        [[0.2795, 0.2805, 0.4400, 0.0000],\n",
              "         [0.2798, 0.3092, 0.4110, 0.0000]]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eff10c9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.557828Z",
          "iopub.status.busy": "2023-08-18T19:43:48.557262Z",
          "iopub.status.idle": "2023-08-18T19:43:48.564098Z",
          "shell.execute_reply": "2023-08-18T19:43:48.563239Z"
        },
        "origin_pos": 18,
        "tab": [
          "pytorch"
        ],
        "id": "0eff10c9",
        "outputId": "55c32f68-acad-4d22-a7a3-7055b2e1bcbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.4109, 0.2794, 0.3097, 0.0000]],\n",
              "\n",
              "        [[0.3960, 0.6040, 0.0000, 0.0000],\n",
              "         [0.2557, 0.1833, 0.2420, 0.3190]]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1d592456",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.567605Z",
          "iopub.status.busy": "2023-08-18T19:43:48.567037Z",
          "iopub.status.idle": "2023-08-18T19:43:48.572146Z",
          "shell.execute_reply": "2023-08-18T19:43:48.571131Z"
        },
        "origin_pos": 23,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d592456",
        "outputId": "ff6d0ee0-1739-4307-b952-be9d6846f240"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[4., 4., 4., 4., 4., 4.],\n",
              "         [4., 4., 4., 4., 4., 4.],\n",
              "         [4., 4., 4., 4., 4., 4.]],\n",
              "\n",
              "        [[4., 4., 4., 4., 4., 4.],\n",
              "         [4., 4., 4., 4., 4., 4.],\n",
              "         [4., 4., 4., 4., 4., 4.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "Q = torch.ones((2, 3, 4))\n",
        "K = torch.ones((2, 4, 6))\n",
        "check_shape(torch.bmm(Q, K), (2, 3, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935cb045",
      "metadata": {
        "id": "935cb045"
      },
      "source": [
        "Scaled Dot Product Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "33207d5f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.575743Z",
          "iopub.status.busy": "2023-08-18T19:43:48.575036Z",
          "iopub.status.idle": "2023-08-18T19:43:48.581055Z",
          "shell.execute_reply": "2023-08-18T19:43:48.580209Z"
        },
        "origin_pos": 28,
        "tab": [
          "pytorch"
        ],
        "id": "33207d5f"
      },
      "outputs": [],
      "source": [
        "class DotProductAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    缩放点积注意力机制\n",
        "\n",
        "    原理：通过计算查询（Query）和键（Key）的点积来得到注意力分数，\n",
        "          然后通过softmax得到注意力权重，最后对值（Value）进行加权求和\n",
        "\n",
        "    公式：Attention(Q, K, V) = softmax(QK^T/√d)V\n",
        "    \"\"\"\n",
        "    def __init__(self, dropout):\n",
        "        \"\"\"\n",
        "        初始化缩放点积注意力\n",
        "\n",
        "        参数:\n",
        "            dropout: dropout比率，用于防止过拟合\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values, valid_lens=None):\n",
        "        \"\"\"\n",
        "        前向传播\n",
        "\n",
        "        参数:\n",
        "            queries: 查询张量，形状为 (batch_size, 查询数量, 特征维度)\n",
        "            keys: 键张量，形状为 (batch_size, 键值对数量, 特征维度)\n",
        "            values: 值张量，形状为 (batch_size, 键值对数量, 输出维度)\n",
        "            valid_lens: 有效长度，用于掩码\n",
        "\n",
        "        返回:\n",
        "            加权求和后的结果，形状为 (batch_size, 查询数量, 输出维度)\n",
        "        \"\"\"\n",
        "        d = queries.shape[-1]\n",
        "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63fab7b",
      "metadata": {
        "id": "c63fab7b"
      },
      "source": [
        "Illustrate how the `DotProductAttention` class works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f40e370d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.594461Z",
          "iopub.status.busy": "2023-08-18T19:43:48.593898Z",
          "iopub.status.idle": "2023-08-18T19:43:48.969221Z",
          "shell.execute_reply": "2023-08-18T19:43:48.968308Z"
        },
        "origin_pos": 37,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "f40e370d",
        "outputId": "d7edd0c7-c687-4053-f72d-e9f4486eab82"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 350x250 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "queries = torch.normal(0, 1, (2, 1, 2))\n",
        "keys = torch.normal(0, 1, (2, 10, 2))\n",
        "values = torch.normal(0, 1, (2, 10, 4))\n",
        "valid_lens = torch.tensor([2, 6])\n",
        "\n",
        "attention = DotProductAttention(dropout=0.5)\n",
        "attention.eval()\n",
        "check_shape(attention(queries, keys, values, valid_lens), (2, 1, 4))\n",
        "\n",
        "show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),\n",
        "                  xlabel='Keys', ylabel='Queries')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae2e4399",
      "metadata": {
        "id": "ae2e4399"
      },
      "source": [
        "Additive Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3a2e6dee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.973108Z",
          "iopub.status.busy": "2023-08-18T19:43:48.972388Z",
          "iopub.status.idle": "2023-08-18T19:43:48.979819Z",
          "shell.execute_reply": "2023-08-18T19:43:48.978914Z"
        },
        "origin_pos": 41,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "3a2e6dee",
        "outputId": "09b01fbc-2c29-4480-c052-ab17ee29ad9c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-2115065557.py, line 39)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2115065557.py\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    queries, keys = self.W_q(queries), self.W_k(keys)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    加性注意力机制（也称为Bahdanau注意力）\n",
        "\n",
        "    原理：通过一个小的神经网络来计算查询和键之间的兼容性分数\n",
        "\n",
        "    公式：注意力分数 = v^T * tanh(W_q * q + W_k * k)\n",
        "\n",
        "    优点：适用于查询和键的维度不同的情况\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_hiddens, dropout, **kwargs):\n",
        "        \"\"\"\n",
        "        初始化加性注意力\n",
        "\n",
        "        参数:\n",
        "            num_hiddens: 隐藏层维度\n",
        "            dropout: dropout比率\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.W_k = nn.LazyLinear(num_hiddens, bias=False)\n",
        "        self.W_q = nn.LazyLinear(num_hiddens, bias=False)\n",
        "        self.w_v = nn.LazyLinear(1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, queries, keys, values, valid_lens):\n",
        "       \"\"\"\n",
        "        前向传播\n",
        "\n",
        "        参数:\n",
        "            queries: 查询张量\n",
        "            keys: 键张量\n",
        "            values: 值张量\n",
        "            valid_lens: 有效长度\n",
        "\n",
        "        返回:\n",
        "            加权求和后的结果\n",
        "        \"\"\"\n",
        "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
        "        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n",
        "        features = torch.tanh(features)\n",
        "        scores = self.w_v(features).squeeze(-1)\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b338adaa",
      "metadata": {
        "id": "b338adaa"
      },
      "source": [
        "See how `AdditiveAttention` works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "bf7a330b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:43:48.996815Z",
          "iopub.status.busy": "2023-08-18T19:43:48.996248Z",
          "iopub.status.idle": "2023-08-18T19:43:49.212301Z",
          "shell.execute_reply": "2023-08-18T19:43:49.211395Z"
        },
        "origin_pos": 50,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "bf7a330b",
        "outputId": "8c18d939-5a85-4e70-ad3e-cf1336b6291f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AdditiveAttention' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1523472570.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdditiveAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AdditiveAttention' is not defined"
          ]
        }
      ],
      "source": [
        "queries = torch.normal(0, 1, (2, 1, 20))\n",
        "\n",
        "attention = AdditiveAttention(num_hiddens=8, dropout=0.1)\n",
        "attention.eval()\n",
        "check_shape(attention(queries, keys, values, valid_lens), (2, 1, 4))\n",
        "\n",
        "show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),\n",
        "                  xlabel='Keys', ylabel='Queries')"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "rise": {
      "autolaunch": true,
      "enable_chalkboard": true,
      "overlay": "<div class='my-top-right'><img height=80px src='http://d2l.ai/_static/logo-with-text.png'/></div><div class='my-top-left'></div>",
      "scroll": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}